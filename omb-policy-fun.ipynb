{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snowballstemmer\n",
    "\n",
    "import fetch_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv already exists, skipping.\n"
     ]
    }
   ],
   "source": [
    "fetch_csv.fetch('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policyNumber</th>\n",
       "      <th>policyTitle</th>\n",
       "      <th>uriPolicyID</th>\n",
       "      <th>ombPolicyID</th>\n",
       "      <th>policyType</th>\n",
       "      <th>policyIssuanceYear</th>\n",
       "      <th>policySunset</th>\n",
       "      <th>policyStatus</th>\n",
       "      <th>reqStatus</th>\n",
       "      <th>precedent</th>\n",
       "      <th>reqID</th>\n",
       "      <th>relatedReqs</th>\n",
       "      <th>issuingBody</th>\n",
       "      <th>policySection</th>\n",
       "      <th>policySubSection</th>\n",
       "      <th>reqText</th>\n",
       "      <th>ombDataCollection</th>\n",
       "      <th>reqVerb</th>\n",
       "      <th>agenciesImpacted</th>\n",
       "      <th>reqDeadline</th>\n",
       "      <th>Citation</th>\n",
       "      <th>Acquisition/Contracts</th>\n",
       "      <th>Human Capital</th>\n",
       "      <th>Cloud</th>\n",
       "      <th>Data Centers</th>\n",
       "      <th>Cybersecurity</th>\n",
       "      <th>Privacy</th>\n",
       "      <th>Shared Services</th>\n",
       "      <th>IT Project Management</th>\n",
       "      <th>Software</th>\n",
       "      <th>Digital Services</th>\n",
       "      <th>Mobile</th>\n",
       "      <th>Hardware/Government Furnished Equipment (GFE)</th>\n",
       "      <th>IT Transparency (Open Data, FOIA, Public Records, etc.)</th>\n",
       "      <th>Agency Statistics</th>\n",
       "      <th>Customer Services</th>\n",
       "      <th>Governance</th>\n",
       "      <th>Financial Systems</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Governance - Org Structure</th>\n",
       "      <th>Governance - Implementation</th>\n",
       "      <th>Data Management/Standards</th>\n",
       "      <th>Definitions</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25 Point Implementation Plan To Reform Federal...</td>\n",
       "      <td>https://www.whitehouse.gov/sites/default/files...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>12/9/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>TBA</td>\n",
       "      <td>1.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Office of the Federal Chief Information Office...</td>\n",
       "      <td>A. Apply “Light Technology” and Shared Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agencies must focus on consolidating existing ...</td>\n",
       "      <td>TBA</td>\n",
       "      <td>Must</td>\n",
       "      <td>All CFO-Act Agencies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25 Point Implementation Plan To Reform Federal...</td>\n",
       "      <td>https://www.whitehouse.gov/sites/default/files...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>12/10/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>TBA</td>\n",
       "      <td>1.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Office of the Federal Chief Information Office...</td>\n",
       "      <td>A. Apply “Light Technology” and Shared Solutions</td>\n",
       "      <td>1.1 Identify agency data center program manage...</td>\n",
       "      <td>Within the next six months, each agency will d...</td>\n",
       "      <td>TBA</td>\n",
       "      <td>Will; Must; Will be</td>\n",
       "      <td>All CFO-Act Agencies</td>\n",
       "      <td>6/8/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25 Point Implementation Plan To Reform Federal...</td>\n",
       "      <td>https://www.whitehouse.gov/sites/default/files...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>12/10/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>TBA</td>\n",
       "      <td>1.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Office of the Federal Chief Information Office...</td>\n",
       "      <td>A. Apply “Light Technology” and Shared Solutions</td>\n",
       "      <td>1.2  Launch a Data Center Consolidation Task F...</td>\n",
       "      <td>Within the next three months, the Federal CIO ...</td>\n",
       "      <td>TBA</td>\n",
       "      <td>Will; Will be</td>\n",
       "      <td>CIOC</td>\n",
       "      <td>3/10/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policyNumber                                        policyTitle  \\\n",
       "0             1  25 Point Implementation Plan To Reform Federal...   \n",
       "1             1  25 Point Implementation Plan To Reform Federal...   \n",
       "2             1  25 Point Implementation Plan To Reform Federal...   \n",
       "\n",
       "                                         uriPolicyID ombPolicyID policyType  \\\n",
       "0  https://www.whitehouse.gov/sites/default/files...         NaN   Strategy   \n",
       "1  https://www.whitehouse.gov/sites/default/files...         NaN   Strategy   \n",
       "2  https://www.whitehouse.gov/sites/default/files...         NaN   Strategy   \n",
       "\n",
       "  policyIssuanceYear policySunset policyStatus reqStatus precedent reqID  \\\n",
       "0          12/9/2010          NaN       Active    Active       TBA  1.01   \n",
       "1         12/10/2010          NaN       Active    Active       TBA  1.02   \n",
       "2         12/10/2010          NaN       Active    Active       TBA  1.03   \n",
       "\n",
       "  relatedReqs                                        issuingBody  \\\n",
       "0         NaN  Office of the Federal Chief Information Office...   \n",
       "1         NaN  Office of the Federal Chief Information Office...   \n",
       "2         NaN  Office of the Federal Chief Information Office...   \n",
       "\n",
       "                                      policySection  \\\n",
       "0  A. Apply “Light Technology” and Shared Solutions   \n",
       "1  A. Apply “Light Technology” and Shared Solutions   \n",
       "2  A. Apply “Light Technology” and Shared Solutions   \n",
       "\n",
       "                                    policySubSection  \\\n",
       "0                                                NaN   \n",
       "1  1.1 Identify agency data center program manage...   \n",
       "2  1.2  Launch a Data Center Consolidation Task F...   \n",
       "\n",
       "                                             reqText ombDataCollection  \\\n",
       "0  Agencies must focus on consolidating existing ...               TBA   \n",
       "1  Within the next six months, each agency will d...               TBA   \n",
       "2  Within the next three months, the Federal CIO ...               TBA   \n",
       "\n",
       "               reqVerb      agenciesImpacted reqDeadline Citation   \\\n",
       "0                 Must  All CFO-Act Agencies         NaN       NaN   \n",
       "1  Will; Must; Will be  All CFO-Act Agencies    6/8/2011       NaN   \n",
       "2        Will; Will be                  CIOC   3/10/2011       NaN   \n",
       "\n",
       "  Acquisition/Contracts Human Capital  Cloud Data Centers  Cybersecurity  \\\n",
       "0                   NaN           NaN   True            x          False   \n",
       "1                   NaN           NaN  False            x          False   \n",
       "2                   NaN           NaN  False            x          False   \n",
       "\n",
       "  Privacy Shared Services IT Project Management Software Digital Services  \\\n",
       "0     NaN               x                   NaN      NaN              NaN   \n",
       "1     NaN             NaN                   NaN      NaN              NaN   \n",
       "2     NaN             NaN                   NaN      NaN              NaN   \n",
       "\n",
       "  Mobile Hardware/Government Furnished Equipment (GFE)  \\\n",
       "0    NaN                                           NaN   \n",
       "1    NaN                                           NaN   \n",
       "2    NaN                                           NaN   \n",
       "\n",
       "  IT Transparency (Open Data, FOIA, Public Records, etc.) Agency Statistics  \\\n",
       "0                                                NaN                    NaN   \n",
       "1                                                NaN                    NaN   \n",
       "2                                                NaN                    NaN   \n",
       "\n",
       "  Customer Services Governance Financial Systems Budget  \\\n",
       "0               NaN        NaN               NaN    NaN   \n",
       "1               NaN        NaN               NaN    NaN   \n",
       "2               NaN        NaN               NaN    NaN   \n",
       "\n",
       "  Governance - Org Structure  Governance - Implementation  \\\n",
       "0                        NaN                        False   \n",
       "1                          x                        False   \n",
       "2                        NaN                         True   \n",
       "\n",
       "  Data Management/Standards Definitions Reporting Other  \n",
       "0                       NaN         NaN       NaN   NaN  \n",
       "1                       NaN         NaN       NaN   NaN  \n",
       "2                       NaN         NaN       NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xbool(val):\n",
    "    if val in ['x', 'X']:\n",
    "        return True\n",
    "    elif val in ['', '0']:\n",
    "        return False\n",
    "    raise ValueError(val)\n",
    "\n",
    "df = pd.read_csv('data.csv', converters={\n",
    "    'Cloud': xbool,\n",
    "    'Cybersecurity': xbool,\n",
    "    'Governance - Implementation': xbool,\n",
    "})\n",
    "pd.set_option('display.max_columns', None)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the requirement texts\n",
    "\n",
    "Right now we are going to be as simple as possible and not even do any stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = \"the and to of a for in or that is with as be an are by on this it its they your\".split(\" \")\n",
    "non_alphabetic_re = re.compile('[\\W0-9_\\-]+')\n",
    "stemmer = snowballstemmer.stemmer('english')\n",
    "\n",
    "def tokenize(text):\n",
    "    if not isinstance(text, str): return []\n",
    "    words = []\n",
    "    for word in text.lower().split():\n",
    "        word = non_alphabetic_re.sub('', word)\n",
    "        if not word: continue\n",
    "        if word in STOP_WORDS: continue\n",
    "        word = stemmer.stemWords([word])[0]\n",
    "        words.append(word)\n",
    "    return words\n",
    "\n",
    "df['reqTextTokenized'] = df['reqText'].map(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "LABEL_TO_TRAIN = 'Cybersecurity'\n",
    "\n",
    "token_counts = Counter()\n",
    "for tokens in df['reqTextTokenized']:\n",
    "    for token in tokens:\n",
    "        token_counts[token] += 1\n",
    "\n",
    "num_examples = df.shape[0]\n",
    "\n",
    "token_counts_df = pd.DataFrame({'token': list(token_counts.keys()), 'count': list(token_counts.values())})\n",
    "token_counts_df.sort_values(by=['count'], ascending=False)\n",
    "\n",
    "vocab = list(token_counts_df['token'][:VOCAB_SIZE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize all the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = np.zeros((VOCAB_SIZE, num_examples))\n",
    "\n",
    "for (i, tokens) in df['reqTextTokenized'].iteritems():\n",
    "    for token in tokens:\n",
    "        if token in vocab:\n",
    "            examples[vocab.index(token)][i] = 1\n",
    "\n",
    "label_ground_truth = df[LABEL_TO_TRAIN].values.reshape(1, num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, dev, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ordering = list(range(df.shape[0]))\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(example_ordering)\n",
    "\n",
    "examples = examples[:, example_ordering]\n",
    "label_ground_truth = label_ground_truth[:, example_ordering]\n",
    "training_set_size = math.floor(num_examples * 0.6)\n",
    "cross_validation_set_size = math.floor(num_examples * 0.2)\n",
    "test_set_start_index = training_set_size + cross_validation_set_size\n",
    "\n",
    "def create_examples_subset(start, end):\n",
    "    return {\n",
    "        'X': examples[:, start:end],\n",
    "        'y': label_ground_truth[:, start:end],\n",
    "    }\n",
    "\n",
    "training_set = create_examples_subset(0, training_set_size)\n",
    "\n",
    "cross_validation_set = create_examples_subset(training_set_size, test_set_start_index)\n",
    "\n",
    "test_set = create_examples_subset(test_set_start_index, examples.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define logistic regression primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBABILITY_THRESHOLD = 0.75\n",
    "\n",
    "# Much of the math/theory behind this can be found at:\n",
    "# https://www.coursera.org/learn/neural-networks-deep-learning/lecture/5sdh6/logistic-regression-gradient-descent\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.power(np.e, -x))\n",
    "\n",
    "# Sanity checks...\n",
    "assert sigmoid(0) == 0.5\n",
    "np.testing.assert_almost_equal(sigmoid(-100), 0)\n",
    "np.testing.assert_almost_equal(sigmoid(100), 1)\n",
    "\n",
    "def compute_activations(X, W, b):\n",
    "    return sigmoid(np.dot(W.T, X) + b)\n",
    "\n",
    "def predict(a):\n",
    "    return a >= PROBABILITY_THRESHOLD\n",
    "\n",
    "def true_positives(predictions, y):\n",
    "    return np.sum((predictions == True) & (y == True))\n",
    "\n",
    "assert true_positives(np.array([[1, 1, 0]]), np.array([[1, 0, 1]])) == 1\n",
    "\n",
    "def false_positives(predictions, y):\n",
    "    return np.sum((predictions == True) & (y == False))\n",
    "\n",
    "assert false_positives(np.array([[1, 1, 0]]), np.array([[1, 0, 1]])) == 1\n",
    "\n",
    "def false_negatives(predictions, y):\n",
    "    return np.sum((predictions == False) & (y == True))\n",
    "\n",
    "assert false_negatives(np.array([[1, 1, 0]]), np.array([[1, 0, 1]])) == 1\n",
    "\n",
    "def accuracy(predictions, y):\n",
    "    correct_predictions = np.sum(predictions == y)\n",
    "    return correct_predictions / y.shape[1]\n",
    "\n",
    "assert accuracy(np.array([[1, 1, 0, 1]]), np.array([[1, 0, 1, 1]])) == 0.5\n",
    "\n",
    "def cost(a, y):\n",
    "    m = y.shape[1]\n",
    "    return np.sum(-(y * np.log(a) + (1 - y) * np.log(1 - a))) / m\n",
    "\n",
    "def compute_gradients(X, W, b, a, y):\n",
    "    m = y.shape[1]\n",
    "    dims = W.shape[0]\n",
    "    dz = a - y\n",
    "    db = np.sum(dz) / m\n",
    "    dW = np.sum(np.repeat(dz, dims, axis=0) * X, axis=1).reshape(dims, 1) / m\n",
    "\n",
    "    return {'db': db, 'dW': dW}\n",
    "\n",
    "def descend_gradient(X, y, num_iterations, learning_rate):\n",
    "    W = np.zeros((VOCAB_SIZE, 1))\n",
    "    b = 0\n",
    "    for i in range(num_iterations):\n",
    "        a = compute_activations(X, W, b)\n",
    "        grads = compute_gradients(X, W, b, a, y)\n",
    "        W -= learning_rate * grads['dW']\n",
    "        b -= learning_rate * grads['db']\n",
    "        yield (i, W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost on iteration 0: 0.7179801508937516 w/ accuracy 0.6747619972799689, 0 tp, 0 fp, and 1674 fn\n",
      "cost on iteration 100: 0.34460801224355553 w/ accuracy 0.7998834272391685, 716 tp, 72 fp, and 958 fn\n",
      "cost on iteration 200: 0.32338477809527094 w/ accuracy 0.8144550223431125, 797 tp, 78 fp, and 877 fn\n",
      "cost on iteration 300: 0.3126204138986876 w/ accuracy 0.8200893724499708, 824 tp, 76 fp, and 850 fn\n",
      "cost on iteration 400: 0.3057027049214824 w/ accuracy 0.8251408587526715, 852 tp, 78 fp, and 822 fn\n",
      "cost on iteration 500: 0.3007351459589023 w/ accuracy 0.827083738099864, 861 tp, 77 fp, and 813 fn\n",
      "cost on iteration 600: 0.29692758359127086 w/ accuracy 0.829415193316495, 875 tp, 79 fp, and 799 fn\n",
      "cost on iteration 700: 0.2938803725336101 w/ accuracy 0.8303866329900913, 881 tp, 80 fp, and 793 fn\n",
      "cost on iteration 800: 0.29136537639921595 w/ accuracy 0.8323295123372838, 893 tp, 82 fp, and 781 fn\n",
      "cost on iteration 900: 0.28924106257067694 w/ accuracy 0.8333009520108802, 897 tp, 81 fp, and 777 fn\n",
      "cost on iteration 1000: 0.28741410180873916 w/ accuracy 0.8352438313580727, 905 tp, 79 fp, and 769 fn\n",
      "cost on iteration 1100: 0.2858200018152509 w/ accuracy 0.8377695745094229, 918 tp, 79 fp, and 756 fn\n",
      "cost on iteration 1200: 0.2844125116578206 w/ accuracy 0.8381581503788614, 922 tp, 81 fp, and 752 fn\n",
      "cost on iteration 1300: 0.28315744511292434 w/ accuracy 0.839323877987177, 929 tp, 82 fp, and 745 fn\n",
      "cost on iteration 1400: 0.2820288915721949 w/ accuracy 0.840101029726054, 932 tp, 81 fp, and 742 fn\n",
      "cost on iteration 1500: 0.2810067919669639 w/ accuracy 0.8404896055954926, 934 tp, 81 fp, and 740 fn\n",
      "cost on iteration 1600: 0.2800753324784313 w/ accuracy 0.841655333203808, 943 tp, 84 fp, and 731 fn\n",
      "cost on iteration 1700: 0.2792218478833887 w/ accuracy 0.8426267728774043, 947 tp, 83 fp, and 727 fn\n",
      "cost on iteration 1800: 0.2784360533728565 w/ accuracy 0.8430153487468428, 949 tp, 83 fp, and 725 fn\n",
      "cost on iteration 1900: 0.27770949432155534 w/ accuracy 0.8443753642898776, 956 tp, 83 fp, and 718 fn\n",
      "cost on iteration 2000: 0.27703514438070753 w/ accuracy 0.8443753642898776, 956 tp, 83 fp, and 718 fn\n"
     ]
    }
   ],
   "source": [
    "for (i, W, b) in descend_gradient(num_iterations=2001, learning_rate=3.0, **training_set):\n",
    "    if i % 100 == 0:\n",
    "        a = compute_activations(training_set['X'], W, b)\n",
    "        curr_cost = cost(a, training_set['y'])\n",
    "        predictions = predict(a)\n",
    "        acc = accuracy(predictions, training_set['y'])\n",
    "        fp = false_positives(predictions, training_set['y'])\n",
    "        fn = false_negatives(predictions, training_set['y'])\n",
    "        tp = true_positives(predictions, training_set['y'])\n",
    "        print(f\"cost on iteration {i}: {curr_cost} w/ accuracy {acc}, {tp} tp, {fp} fp, and {fn} fn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- example row 2535\n",
      "Under the authority of the Attorney General, the Director of the Federal Bureau of Investigation (FBI) shall be responsible for the operation of the NCIJTF. This authority does not allow the Director of the FBI to direct the operations of other agencies. The Director of the FBI shall ensure that participants share the methodology and, to the extent appropriate, case information related to criminal cyber intrusion investigations among law enforcement organizations represented in the NCIJTF in accordance with paragraphs 32 - 33. [Ref. reqs. 1143.52 and 1143.53]\n",
      "['under', 'author', 'attorney', 'general', 'director', 'feder', 'bureau', 'investig', 'fbi', 'shall', 'respons', 'oper', 'ncijtf', 'author', 'doe', 'not', 'allow', 'director', 'fbi', 'direct', 'oper', 'other', 'agenc', 'director', 'fbi', 'shall', 'ensur', 'particip', 'share', 'methodolog', 'extent', 'appropri', 'case', 'inform', 'relat', 'crimin', 'cyber', 'intrus', 'investig', 'among', 'law', 'enforc', 'organ', 'repres', 'ncijtf', 'accord', 'paragraph', 'ref', 'req']\n"
     ]
    }
   ],
   "source": [
    "def print_true_positives(maximum=10):\n",
    "    found = 0\n",
    "    for i in range(training_set_size):\n",
    "        if predictions[0][i] and training_set['y'][0][i]:\n",
    "            orig_index = example_ordering.index(i)\n",
    "            df_row = df.loc[example_ordering[i]]\n",
    "            print(f'-- example row {orig_index}')\n",
    "            print(df_row['reqText'])\n",
    "            print(df_row['reqTextTokenized'])\n",
    "            assert df_row[LABEL_TO_TRAIN] == True\n",
    "            found += 1\n",
    "            if found == maximum:\n",
    "                return\n",
    "\n",
    "print_true_positives(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
