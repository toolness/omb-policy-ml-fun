{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snowballstemmer\n",
    "\n",
    "import fetch_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv already exists, skipping.\n"
     ]
    }
   ],
   "source": [
    "fetch_csv.fetch('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policyNumber</th>\n",
       "      <th>policyTitle</th>\n",
       "      <th>uriPolicyID</th>\n",
       "      <th>ombPolicyID</th>\n",
       "      <th>policyType</th>\n",
       "      <th>policyIssuanceYear</th>\n",
       "      <th>policySunset</th>\n",
       "      <th>policyStatus</th>\n",
       "      <th>reqStatus</th>\n",
       "      <th>precedent</th>\n",
       "      <th>reqID</th>\n",
       "      <th>relatedReqs</th>\n",
       "      <th>issuingBody</th>\n",
       "      <th>policySection</th>\n",
       "      <th>policySubSection</th>\n",
       "      <th>reqText</th>\n",
       "      <th>ombDataCollection</th>\n",
       "      <th>reqVerb</th>\n",
       "      <th>agenciesImpacted</th>\n",
       "      <th>reqDeadline</th>\n",
       "      <th>Citation</th>\n",
       "      <th>Acquisition/Contracts</th>\n",
       "      <th>Human Capital</th>\n",
       "      <th>Cloud</th>\n",
       "      <th>Data Centers</th>\n",
       "      <th>Cybersecurity</th>\n",
       "      <th>Privacy</th>\n",
       "      <th>Shared Services</th>\n",
       "      <th>IT Project Management</th>\n",
       "      <th>Software</th>\n",
       "      <th>Digital Services</th>\n",
       "      <th>Mobile</th>\n",
       "      <th>Hardware/Government Furnished Equipment (GFE)</th>\n",
       "      <th>IT Transparency (Open Data, FOIA, Public Records, etc.)</th>\n",
       "      <th>Agency Statistics</th>\n",
       "      <th>Customer Services</th>\n",
       "      <th>Governance</th>\n",
       "      <th>Financial Systems</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Governance - Org Structure</th>\n",
       "      <th>Governance - Implementation</th>\n",
       "      <th>Data Management/Standards</th>\n",
       "      <th>Definitions</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25 Point Implementation Plan To Reform Federal...</td>\n",
       "      <td>https://www.whitehouse.gov/sites/default/files...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>12/9/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>TBA</td>\n",
       "      <td>1.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Office of the Federal Chief Information Office...</td>\n",
       "      <td>A. Apply “Light Technology” and Shared Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agencies must focus on consolidating existing ...</td>\n",
       "      <td>TBA</td>\n",
       "      <td>Must</td>\n",
       "      <td>All CFO-Act Agencies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25 Point Implementation Plan To Reform Federal...</td>\n",
       "      <td>https://www.whitehouse.gov/sites/default/files...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>12/10/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>TBA</td>\n",
       "      <td>1.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Office of the Federal Chief Information Office...</td>\n",
       "      <td>A. Apply “Light Technology” and Shared Solutions</td>\n",
       "      <td>1.1 Identify agency data center program manage...</td>\n",
       "      <td>Within the next six months, each agency will d...</td>\n",
       "      <td>TBA</td>\n",
       "      <td>Will; Must; Will be</td>\n",
       "      <td>All CFO-Act Agencies</td>\n",
       "      <td>6/8/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25 Point Implementation Plan To Reform Federal...</td>\n",
       "      <td>https://www.whitehouse.gov/sites/default/files...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>12/10/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>TBA</td>\n",
       "      <td>1.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Office of the Federal Chief Information Office...</td>\n",
       "      <td>A. Apply “Light Technology” and Shared Solutions</td>\n",
       "      <td>1.2  Launch a Data Center Consolidation Task F...</td>\n",
       "      <td>Within the next three months, the Federal CIO ...</td>\n",
       "      <td>TBA</td>\n",
       "      <td>Will; Will be</td>\n",
       "      <td>CIOC</td>\n",
       "      <td>3/10/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policyNumber                                        policyTitle  \\\n",
       "0             1  25 Point Implementation Plan To Reform Federal...   \n",
       "1             1  25 Point Implementation Plan To Reform Federal...   \n",
       "2             1  25 Point Implementation Plan To Reform Federal...   \n",
       "\n",
       "                                         uriPolicyID ombPolicyID policyType  \\\n",
       "0  https://www.whitehouse.gov/sites/default/files...         NaN   Strategy   \n",
       "1  https://www.whitehouse.gov/sites/default/files...         NaN   Strategy   \n",
       "2  https://www.whitehouse.gov/sites/default/files...         NaN   Strategy   \n",
       "\n",
       "  policyIssuanceYear policySunset policyStatus reqStatus precedent reqID  \\\n",
       "0          12/9/2010          NaN       Active    Active       TBA  1.01   \n",
       "1         12/10/2010          NaN       Active    Active       TBA  1.02   \n",
       "2         12/10/2010          NaN       Active    Active       TBA  1.03   \n",
       "\n",
       "  relatedReqs                                        issuingBody  \\\n",
       "0         NaN  Office of the Federal Chief Information Office...   \n",
       "1         NaN  Office of the Federal Chief Information Office...   \n",
       "2         NaN  Office of the Federal Chief Information Office...   \n",
       "\n",
       "                                      policySection  \\\n",
       "0  A. Apply “Light Technology” and Shared Solutions   \n",
       "1  A. Apply “Light Technology” and Shared Solutions   \n",
       "2  A. Apply “Light Technology” and Shared Solutions   \n",
       "\n",
       "                                    policySubSection  \\\n",
       "0                                                NaN   \n",
       "1  1.1 Identify agency data center program manage...   \n",
       "2  1.2  Launch a Data Center Consolidation Task F...   \n",
       "\n",
       "                                             reqText ombDataCollection  \\\n",
       "0  Agencies must focus on consolidating existing ...               TBA   \n",
       "1  Within the next six months, each agency will d...               TBA   \n",
       "2  Within the next three months, the Federal CIO ...               TBA   \n",
       "\n",
       "               reqVerb      agenciesImpacted reqDeadline Citation   \\\n",
       "0                 Must  All CFO-Act Agencies         NaN       NaN   \n",
       "1  Will; Must; Will be  All CFO-Act Agencies    6/8/2011       NaN   \n",
       "2        Will; Will be                  CIOC   3/10/2011       NaN   \n",
       "\n",
       "  Acquisition/Contracts Human Capital  Cloud Data Centers  Cybersecurity  \\\n",
       "0                   NaN           NaN   True            x          False   \n",
       "1                   NaN           NaN  False            x          False   \n",
       "2                   NaN           NaN  False            x          False   \n",
       "\n",
       "  Privacy Shared Services IT Project Management Software Digital Services  \\\n",
       "0     NaN               x                   NaN      NaN              NaN   \n",
       "1     NaN             NaN                   NaN      NaN              NaN   \n",
       "2     NaN             NaN                   NaN      NaN              NaN   \n",
       "\n",
       "  Mobile Hardware/Government Furnished Equipment (GFE)  \\\n",
       "0    NaN                                           NaN   \n",
       "1    NaN                                           NaN   \n",
       "2    NaN                                           NaN   \n",
       "\n",
       "  IT Transparency (Open Data, FOIA, Public Records, etc.) Agency Statistics  \\\n",
       "0                                                NaN                    NaN   \n",
       "1                                                NaN                    NaN   \n",
       "2                                                NaN                    NaN   \n",
       "\n",
       "  Customer Services Governance Financial Systems Budget  \\\n",
       "0               NaN        NaN               NaN    NaN   \n",
       "1               NaN        NaN               NaN    NaN   \n",
       "2               NaN        NaN               NaN    NaN   \n",
       "\n",
       "  Governance - Org Structure  Governance - Implementation  \\\n",
       "0                        NaN                        False   \n",
       "1                          x                        False   \n",
       "2                        NaN                         True   \n",
       "\n",
       "  Data Management/Standards Definitions Reporting Other  \n",
       "0                       NaN         NaN       NaN   NaN  \n",
       "1                       NaN         NaN       NaN   NaN  \n",
       "2                       NaN         NaN       NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xbool(val):\n",
    "    if val in ['x', 'X']:\n",
    "        return True\n",
    "    elif val in ['', '0']:\n",
    "        return False\n",
    "    raise ValueError(val)\n",
    "\n",
    "df = pd.read_csv('data.csv', converters={\n",
    "    'Cloud': xbool,\n",
    "    'Cybersecurity': xbool,\n",
    "    'Governance - Implementation': xbool,\n",
    "})\n",
    "pd.set_option('display.max_columns', None)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the requirement texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = \"the and to of a for in or that is with as be an are by on this it its they your\".split(\" \")\n",
    "non_alphabetic_re = re.compile('[\\W0-9_\\-]+')\n",
    "stemmer = snowballstemmer.stemmer('english')\n",
    "\n",
    "def tokenize(text):\n",
    "    if not isinstance(text, str): return []\n",
    "    words = []\n",
    "    for word in text.lower().split():\n",
    "        word = non_alphabetic_re.sub('', word)\n",
    "        if not word: continue\n",
    "        if word in STOP_WORDS: continue\n",
    "        word = stemmer.stemWords([word])[0]\n",
    "        words.append(word)\n",
    "    return words\n",
    "\n",
    "df['reqTextTokenized'] = df['reqText'].map(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1500\n",
    "\n",
    "token_counts = Counter()\n",
    "for tokens in df['reqTextTokenized']:\n",
    "    for token in tokens:\n",
    "        token_counts[token] += 1\n",
    "\n",
    "num_examples = df.shape[0]\n",
    "\n",
    "token_counts_df = pd.DataFrame({'token': list(token_counts.keys()), 'count': list(token_counts.values())})\n",
    "token_counts_df.sort_values(by=['count'], ascending=False)\n",
    "\n",
    "vocab = list(token_counts_df['token'][:VOCAB_SIZE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize all the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = np.zeros((VOCAB_SIZE, num_examples))\n",
    "\n",
    "for (i, tokens) in df['reqTextTokenized'].iteritems():\n",
    "    for token in tokens:\n",
    "        if token in vocab:\n",
    "            examples[vocab.index(token)][i] += 1\n",
    "\n",
    "def center_and_rescale(examples):\n",
    "    \"\"\"\n",
    "    For each dimension in each example, subtract the mean and divide\n",
    "    by the standard deviation. This is taught as a reasonable\n",
    "    strategy to speed up gradient descent in Coursera's ML class.\n",
    "\n",
    "    In practice it allows us to achieve in 300 iterations of\n",
    "    gradient descent what once took 2000.\n",
    "    \"\"\"\n",
    "\n",
    "    dims = examples.shape[0]\n",
    "    m = examples.shape[1]\n",
    "    means = (np.sum(examples, axis=1) / m).reshape(dims, 1)\n",
    "    stddevs = np.std(examples, axis=1).reshape(dims, 1)\n",
    "    return (examples - means) / stddevs\n",
    "\n",
    "examples = center_and_rescale(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide on a label to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL_TO_TRAIN = 'Cybersecurity'\n",
    "\n",
    "label_ground_truth = df[LABEL_TO_TRAIN].values.reshape(1, num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, dev, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_ordering = list(range(df.shape[0]))\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(example_ordering)\n",
    "\n",
    "examples = examples[:, example_ordering]\n",
    "label_ground_truth = label_ground_truth[:, example_ordering]\n",
    "training_set_size = math.floor(num_examples * 0.6)\n",
    "cross_validation_set_size = math.floor(num_examples * 0.2)\n",
    "test_set_start_index = training_set_size + cross_validation_set_size\n",
    "\n",
    "def create_examples_subset(start, end):\n",
    "    return {\n",
    "        'X': examples[:, start:end],\n",
    "        'y': label_ground_truth[:, start:end],\n",
    "    }\n",
    "\n",
    "training_set = create_examples_subset(0, training_set_size)\n",
    "\n",
    "cross_validation_set = create_examples_subset(training_set_size, test_set_start_index)\n",
    "\n",
    "test_set = create_examples_subset(test_set_start_index, examples.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define logistic regression primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROBABILITY_THRESHOLD = 0.75\n",
    "\n",
    "# Much of the math/theory behind this can be found at:\n",
    "# https://www.coursera.org/learn/neural-networks-deep-learning/lecture/5sdh6/logistic-regression-gradient-descent\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.power(np.e, -x))\n",
    "\n",
    "# Sanity checks...\n",
    "assert sigmoid(0) == 0.5\n",
    "np.testing.assert_almost_equal(sigmoid(-100), 0)\n",
    "np.testing.assert_almost_equal(sigmoid(100), 1)\n",
    "\n",
    "def compute_activations(X, W, b):\n",
    "    return sigmoid(np.dot(W.T, X) + b)\n",
    "\n",
    "def predict(a):\n",
    "    return a >= PROBABILITY_THRESHOLD\n",
    "\n",
    "def true_positives(predictions, y):\n",
    "    return np.sum((predictions == True) & (y == True))\n",
    "\n",
    "assert true_positives(np.array([[1, 1, 0]]), np.array([[1, 0, 1]])) == 1\n",
    "\n",
    "def false_positives(predictions, y):\n",
    "    return np.sum((predictions == True) & (y == False))\n",
    "\n",
    "assert false_positives(np.array([[1, 1, 0]]), np.array([[1, 0, 1]])) == 1\n",
    "\n",
    "def false_negatives(predictions, y):\n",
    "    return np.sum((predictions == False) & (y == True))\n",
    "\n",
    "assert false_negatives(np.array([[1, 1, 0]]), np.array([[1, 0, 1]])) == 1\n",
    "\n",
    "def accuracy(predictions, y):\n",
    "    correct_predictions = np.sum(predictions == y)\n",
    "    return correct_predictions / y.shape[1]\n",
    "\n",
    "assert accuracy(np.array([[1, 1, 0, 1]]), np.array([[1, 0, 1, 1]])) == 0.5\n",
    "\n",
    "def cost(a, y):\n",
    "    m = y.shape[1]\n",
    "\n",
    "    # TODO: I'm not sure if this is the best solution, but sometimes the\n",
    "    # result of the activation function is exactly 0 or 1, which makes us\n",
    "    # return NaN, so we'll clip our values to be within the open interval\n",
    "    # (0, 1).\n",
    "    a = np.clip(a, 1e-7, 1 - 1e-7)\n",
    "\n",
    "    return np.sum(-(y * np.log(a) + (1 - y) * np.log(1 - a))) / m\n",
    "\n",
    "def compute_gradients(X, W, b, a, y):\n",
    "    m = y.shape[1]\n",
    "    dims = W.shape[0]\n",
    "    dz = a - y\n",
    "    db = np.sum(dz) / m\n",
    "    dW = np.sum(np.repeat(dz, dims, axis=0) * X, axis=1).reshape(dims, 1) / m\n",
    "\n",
    "    return {'db': db, 'dW': dW}\n",
    "\n",
    "def descend_gradient(X, y, num_iterations, learning_rate):\n",
    "    W = np.zeros((VOCAB_SIZE, 1))\n",
    "    b = 0\n",
    "    for i in range(num_iterations):\n",
    "        a = compute_activations(X, W, b)\n",
    "        grads = compute_gradients(X, W, b, a, y)\n",
    "        W -= learning_rate * grads['dW']\n",
    "        b -= learning_rate * grads['db']\n",
    "        yield (i, W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost on iteration 0: 0.429086413055763 w/ accuracy 0.8404896055954926, 1106 tp, 253 fp, and 568 fn\n",
      "cost on iteration 100: 0.1336331227141149 w/ accuracy 0.9220905381775791, 1305 tp, 32 fp, and 369 fn\n",
      "cost on iteration 200: 0.11780483479177055 w/ accuracy 0.9314163590441034, 1351 tp, 30 fp, and 323 fn\n",
      "cost on iteration 300: 0.10928065041714953 w/ accuracy 0.9364678453468039, 1376 tp, 29 fp, and 298 fn\n"
     ]
    }
   ],
   "source": [
    "for (i, W, b) in descend_gradient(num_iterations=301, learning_rate=3.0, **training_set):\n",
    "    if i % 100 == 0:\n",
    "        a = compute_activations(training_set['X'], W, b)\n",
    "        curr_cost = cost(a, training_set['y'])\n",
    "        predictions = predict(a)\n",
    "        acc = accuracy(predictions, training_set['y'])\n",
    "        fp = false_positives(predictions, training_set['y'])\n",
    "        fn = false_negatives(predictions, training_set['y'])\n",
    "        tp = true_positives(predictions, training_set['y'])\n",
    "        print(f\"cost on iteration {i}: {curr_cost} w/ accuracy {acc}, {tp} tp, {fp} fp, and {fn} fn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- example row 6855\n",
      "[The following is part of a Reporting Template for SAOPs for annual FISMA and privacy reporting, ref. Reqs. 1357.01-1357.06] \n",
      "5. PIA and Web Privacy Policies and Processes \n",
      "Section 208 of the E-Government Act requires that agencies (a) conduct PIAs under appropriate circumstances, (b) post web privacy policies on their web sites, and (c) ensure machine-readability of web privacy policies. \n",
      "\n",
      "Does the agency have a written policy or process for each of the following? Indicate Yes or No for each item in the table below. \n",
      "\n",
      "PIA Policies \n",
      "a. Determining whether a PIA is needed \n",
      "b. Conducting a PIA \n",
      "c. Evaluating changes in business process or technology that the PIA indicates may be required\n",
      "d. Ensuring that systems owners and privacy and information technology experts participate in conducting the PIA \n",
      "e. Making PIAs available to the public in the required circumstances \n",
      "f. Making PIAs available in other than required circumstances \n",
      "\n",
      "Web Policies \n",
      "g. Determining continued compliance with stated web policies \n",
      "h. Requiring machine-readability of public-facing agency web sites (i.e. use of P3P) \n",
      "\n",
      "['follow', 'part', 'report', 'templat', 'saop', 'annual', 'fisma', 'privaci', 'report', 'ref', 'req', 'pia', 'web', 'privaci', 'polici', 'process', 'section', 'egovern', 'act', 'requir', 'agenc', 'conduct', 'pia', 'under', 'appropri', 'circumst', 'b', 'post', 'web', 'privaci', 'polici', 'their', 'web', 'site', 'c', 'ensur', 'machineread', 'web', 'privaci', 'polici', 'doe', 'agenc', 'have', 'written', 'polici', 'process', 'each', 'follow', 'indic', 'yes', 'no', 'each', 'item', 'tabl', 'below', 'pia', 'polici', 'determin', 'whether', 'pia', 'need', 'b', 'conduct', 'pia', 'c', 'evalu', 'chang', 'busi', 'process', 'technolog', 'pia', 'indic', 'may', 'requir', 'd', 'ensur', 'system', 'owner', 'privaci', 'inform', 'technolog', 'expert', 'particip', 'conduct', 'pia', 'e', 'make', 'pia', 'avail', 'public', 'requir', 'circumst', 'f', 'make', 'pia', 'avail', 'other', 'than', 'requir', 'circumst', 'web', 'polici', 'g', 'determin', 'continu', 'complianc', 'state', 'web', 'polici', 'h', 'requir', 'machineread', 'publicfac', 'agenc', 'web', 'site', 'ie', 'use', 'pp']\n"
     ]
    }
   ],
   "source": [
    "def print_true_positives(maximum=10):\n",
    "    found = 0\n",
    "    for i in range(training_set_size):\n",
    "        if predictions[0][i] and training_set['y'][0][i]:\n",
    "            orig_index = example_ordering.index(i)\n",
    "            df_row = df.loc[example_ordering[i]]\n",
    "            print(f'-- example row {orig_index}')\n",
    "            print(df_row['reqText'])\n",
    "            print(df_row['reqTextTokenized'])\n",
    "            assert df_row[LABEL_TO_TRAIN] == True\n",
    "            found += 1\n",
    "            if found == maximum:\n",
    "                return\n",
    "\n",
    "print_true_positives(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for cross validation set: 0.9511206265392399 w/ accuracy 0.8011661807580175, 342 tp, 135 fp, and 206 fn\n"
     ]
    }
   ],
   "source": [
    "def run_cross_validation_set():\n",
    "    a = compute_activations(cross_validation_set['X'], W, b)\n",
    "    curr_cost = cost(a, cross_validation_set['y'])\n",
    "    predictions = predict(a)\n",
    "    acc = accuracy(predictions, cross_validation_set['y'])\n",
    "    fp = false_positives(predictions, cross_validation_set['y'])\n",
    "    fn = false_negatives(predictions, cross_validation_set['y'])\n",
    "    tp = true_positives(predictions, cross_validation_set['y'])\n",
    "    print(f\"cost for cross validation set: {curr_cost} w/ accuracy {acc}, {tp} tp, {fp} fp, and {fn} fn\")\n",
    "\n",
    "run_cross_validation_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
