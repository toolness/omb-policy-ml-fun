{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snowballstemmer\n",
    "\n",
    "import fetch_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv already exists, skipping.\n"
     ]
    }
   ],
   "source": [
    "fetch_csv.fetch('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policyNumber</th>\n",
       "      <th>policyTitle</th>\n",
       "      <th>uriPolicyID</th>\n",
       "      <th>ombPolicyID</th>\n",
       "      <th>policyType</th>\n",
       "      <th>policyIssuanceYear</th>\n",
       "      <th>policySunset</th>\n",
       "      <th>policyStatus</th>\n",
       "      <th>reqStatus</th>\n",
       "      <th>precedent</th>\n",
       "      <th>reqID</th>\n",
       "      <th>relatedReqs</th>\n",
       "      <th>issuingBody</th>\n",
       "      <th>policySection</th>\n",
       "      <th>policySubSection</th>\n",
       "      <th>reqText</th>\n",
       "      <th>ombDataCollection</th>\n",
       "      <th>reqVerb</th>\n",
       "      <th>agenciesImpacted</th>\n",
       "      <th>reqDeadline</th>\n",
       "      <th>Citation</th>\n",
       "      <th>Acquisition/Contracts</th>\n",
       "      <th>Human Capital</th>\n",
       "      <th>Cloud</th>\n",
       "      <th>Data Centers</th>\n",
       "      <th>Cybersecurity</th>\n",
       "      <th>Privacy</th>\n",
       "      <th>Shared Services</th>\n",
       "      <th>IT Project Management</th>\n",
       "      <th>Software</th>\n",
       "      <th>Digital Services</th>\n",
       "      <th>Mobile</th>\n",
       "      <th>Hardware/Government Furnished Equipment (GFE)</th>\n",
       "      <th>IT Transparency (Open Data, FOIA, Public Records, etc.)</th>\n",
       "      <th>Agency Statistics</th>\n",
       "      <th>Customer Services</th>\n",
       "      <th>Governance</th>\n",
       "      <th>Financial Systems</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Governance - Org Structure</th>\n",
       "      <th>Governance - Implementation</th>\n",
       "      <th>Data Management/Standards</th>\n",
       "      <th>Definitions</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25 Point Implementation Plan To Reform Federal...</td>\n",
       "      <td>https://www.whitehouse.gov/sites/default/files...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>12/9/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>TBA</td>\n",
       "      <td>1.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Office of the Federal Chief Information Office...</td>\n",
       "      <td>A. Apply “Light Technology” and Shared Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agencies must focus on consolidating existing ...</td>\n",
       "      <td>TBA</td>\n",
       "      <td>Must</td>\n",
       "      <td>All CFO-Act Agencies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25 Point Implementation Plan To Reform Federal...</td>\n",
       "      <td>https://www.whitehouse.gov/sites/default/files...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>12/10/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>TBA</td>\n",
       "      <td>1.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Office of the Federal Chief Information Office...</td>\n",
       "      <td>A. Apply “Light Technology” and Shared Solutions</td>\n",
       "      <td>1.1 Identify agency data center program manage...</td>\n",
       "      <td>Within the next six months, each agency will d...</td>\n",
       "      <td>TBA</td>\n",
       "      <td>Will; Must; Will be</td>\n",
       "      <td>All CFO-Act Agencies</td>\n",
       "      <td>6/8/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25 Point Implementation Plan To Reform Federal...</td>\n",
       "      <td>https://www.whitehouse.gov/sites/default/files...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>12/10/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>TBA</td>\n",
       "      <td>1.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Office of the Federal Chief Information Office...</td>\n",
       "      <td>A. Apply “Light Technology” and Shared Solutions</td>\n",
       "      <td>1.2  Launch a Data Center Consolidation Task F...</td>\n",
       "      <td>Within the next three months, the Federal CIO ...</td>\n",
       "      <td>TBA</td>\n",
       "      <td>Will; Will be</td>\n",
       "      <td>CIOC</td>\n",
       "      <td>3/10/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policyNumber                                        policyTitle  \\\n",
       "0             1  25 Point Implementation Plan To Reform Federal...   \n",
       "1             1  25 Point Implementation Plan To Reform Federal...   \n",
       "2             1  25 Point Implementation Plan To Reform Federal...   \n",
       "\n",
       "                                         uriPolicyID ombPolicyID policyType  \\\n",
       "0  https://www.whitehouse.gov/sites/default/files...         NaN   Strategy   \n",
       "1  https://www.whitehouse.gov/sites/default/files...         NaN   Strategy   \n",
       "2  https://www.whitehouse.gov/sites/default/files...         NaN   Strategy   \n",
       "\n",
       "  policyIssuanceYear policySunset policyStatus reqStatus precedent reqID  \\\n",
       "0          12/9/2010          NaN       Active    Active       TBA  1.01   \n",
       "1         12/10/2010          NaN       Active    Active       TBA  1.02   \n",
       "2         12/10/2010          NaN       Active    Active       TBA  1.03   \n",
       "\n",
       "  relatedReqs                                        issuingBody  \\\n",
       "0         NaN  Office of the Federal Chief Information Office...   \n",
       "1         NaN  Office of the Federal Chief Information Office...   \n",
       "2         NaN  Office of the Federal Chief Information Office...   \n",
       "\n",
       "                                      policySection  \\\n",
       "0  A. Apply “Light Technology” and Shared Solutions   \n",
       "1  A. Apply “Light Technology” and Shared Solutions   \n",
       "2  A. Apply “Light Technology” and Shared Solutions   \n",
       "\n",
       "                                    policySubSection  \\\n",
       "0                                                NaN   \n",
       "1  1.1 Identify agency data center program manage...   \n",
       "2  1.2  Launch a Data Center Consolidation Task F...   \n",
       "\n",
       "                                             reqText ombDataCollection  \\\n",
       "0  Agencies must focus on consolidating existing ...               TBA   \n",
       "1  Within the next six months, each agency will d...               TBA   \n",
       "2  Within the next three months, the Federal CIO ...               TBA   \n",
       "\n",
       "               reqVerb      agenciesImpacted reqDeadline Citation   \\\n",
       "0                 Must  All CFO-Act Agencies         NaN       NaN   \n",
       "1  Will; Must; Will be  All CFO-Act Agencies    6/8/2011       NaN   \n",
       "2        Will; Will be                  CIOC   3/10/2011       NaN   \n",
       "\n",
       "  Acquisition/Contracts Human Capital  Cloud Data Centers  Cybersecurity  \\\n",
       "0                   NaN           NaN   True            x          False   \n",
       "1                   NaN           NaN  False            x          False   \n",
       "2                   NaN           NaN  False            x          False   \n",
       "\n",
       "  Privacy Shared Services IT Project Management Software Digital Services  \\\n",
       "0     NaN               x                   NaN      NaN              NaN   \n",
       "1     NaN             NaN                   NaN      NaN              NaN   \n",
       "2     NaN             NaN                   NaN      NaN              NaN   \n",
       "\n",
       "  Mobile Hardware/Government Furnished Equipment (GFE)  \\\n",
       "0    NaN                                           NaN   \n",
       "1    NaN                                           NaN   \n",
       "2    NaN                                           NaN   \n",
       "\n",
       "  IT Transparency (Open Data, FOIA, Public Records, etc.) Agency Statistics  \\\n",
       "0                                                NaN                    NaN   \n",
       "1                                                NaN                    NaN   \n",
       "2                                                NaN                    NaN   \n",
       "\n",
       "  Customer Services Governance Financial Systems Budget  \\\n",
       "0               NaN        NaN               NaN    NaN   \n",
       "1               NaN        NaN               NaN    NaN   \n",
       "2               NaN        NaN               NaN    NaN   \n",
       "\n",
       "  Governance - Org Structure  Governance - Implementation  \\\n",
       "0                        NaN                        False   \n",
       "1                          x                        False   \n",
       "2                        NaN                         True   \n",
       "\n",
       "  Data Management/Standards Definitions Reporting Other  \n",
       "0                       NaN         NaN       NaN   NaN  \n",
       "1                       NaN         NaN       NaN   NaN  \n",
       "2                       NaN         NaN       NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xbool(val):\n",
    "    if val in ['x', 'X']:\n",
    "        return True\n",
    "    elif val in ['', '0']:\n",
    "        return False\n",
    "    raise ValueError(val)\n",
    "\n",
    "df = pd.read_csv('data.csv', converters={\n",
    "    'Cloud': xbool,\n",
    "    'Cybersecurity': xbool,\n",
    "    'Governance - Implementation': xbool,\n",
    "})\n",
    "pd.set_option('display.max_columns', None)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the requirement texts\n",
    "\n",
    "Right now we are going to be as simple as possible and not even do any stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = \"the and to of a for in or that is with as be an are by on this it its they your\".split(\" \")\n",
    "non_alphabetic_re = re.compile('[\\W0-9_\\-]+')\n",
    "stemmer = snowballstemmer.stemmer('english')\n",
    "\n",
    "def tokenize(text):\n",
    "    if not isinstance(text, str): return []\n",
    "    words = []\n",
    "    for word in text.lower().split():\n",
    "        word = non_alphabetic_re.sub('', word)\n",
    "        if not word: continue\n",
    "        if word in STOP_WORDS: continue\n",
    "        word = stemmer.stemWords([word])[0]\n",
    "        words.append(word)\n",
    "    return words\n",
    "\n",
    "df['reqTextTokenized'] = df['reqText'].map(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "LABEL_TO_TRAIN = 'Cybersecurity'\n",
    "\n",
    "token_counts = Counter()\n",
    "for tokens in df['reqTextTokenized']:\n",
    "    for token in tokens:\n",
    "        token_counts[token] += 1\n",
    "\n",
    "num_examples = df.shape[0]\n",
    "\n",
    "token_counts_df = pd.DataFrame({'token': list(token_counts.keys()), 'count': list(token_counts.values())})\n",
    "token_counts_df.sort_values(by=['count'], ascending=False)\n",
    "\n",
    "vocab = list(token_counts_df['token'][:VOCAB_SIZE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize all the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = np.zeros((VOCAB_SIZE, num_examples))\n",
    "\n",
    "for (i, tokens) in df['reqTextTokenized'].iteritems():\n",
    "    for token in tokens:\n",
    "        if token in vocab:\n",
    "            examples[vocab.index(token)][i] = 1\n",
    "\n",
    "label_ground_truth = df[LABEL_TO_TRAIN].values.reshape(1, num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, dev, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ordering = list(range(df.shape[0]))\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(example_ordering)\n",
    "\n",
    "examples = examples[:, example_ordering]\n",
    "label_ground_truth = label_ground_truth[:, example_ordering]\n",
    "training_set_size = math.floor(num_examples * 0.6)\n",
    "cross_validation_set_size = math.floor(num_examples * 0.2)\n",
    "test_set_start_index = training_set_size + cross_validation_set_size\n",
    "\n",
    "def create_examples_subset(start, end):\n",
    "    return {\n",
    "        'X': examples[:, start:end],\n",
    "        'y': label_ground_truth[:, start:end],\n",
    "    }\n",
    "\n",
    "training_set = create_examples_subset(0, training_set_size)\n",
    "\n",
    "cross_validation_set = create_examples_subset(training_set_size, test_set_start_index)\n",
    "\n",
    "test_set = create_examples_subset(test_set_start_index, examples.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define logistic regression primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBABILITY_THRESHOLD = 0.75\n",
    "\n",
    "# Much of the math/theory behind this can be found at:\n",
    "# https://www.coursera.org/learn/neural-networks-deep-learning/lecture/5sdh6/logistic-regression-gradient-descent\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.power(np.e, -x))\n",
    "\n",
    "# Sanity checks...\n",
    "assert sigmoid(0) == 0.5\n",
    "np.testing.assert_almost_equal(sigmoid(-100), 0)\n",
    "np.testing.assert_almost_equal(sigmoid(100), 1)\n",
    "\n",
    "def compute_activations(X, W, b):\n",
    "    return sigmoid(np.dot(W.T, X) + b)\n",
    "\n",
    "def predict(a):\n",
    "    return a >= PROBABILITY_THRESHOLD\n",
    "\n",
    "def true_positives(predictions, y):\n",
    "    return np.sum((predictions == True) & (y == True))\n",
    "\n",
    "assert true_positives(np.array([[1, 1, 0]]), np.array([[1, 0, 1]])) == 1\n",
    "\n",
    "def false_positives(predictions, y):\n",
    "    return np.sum((predictions == True) & (y == False))\n",
    "\n",
    "assert false_positives(np.array([[1, 1, 0]]), np.array([[1, 0, 1]])) == 1\n",
    "\n",
    "def false_negatives(predictions, y):\n",
    "    return np.sum((predictions == False) & (y == True))\n",
    "\n",
    "assert false_negatives(np.array([[1, 1, 0]]), np.array([[1, 0, 1]])) == 1\n",
    "\n",
    "def accuracy(predictions, y):\n",
    "    correct_predictions = np.sum(predictions == y)\n",
    "    return correct_predictions / y.shape[1]\n",
    "\n",
    "assert accuracy(np.array([[1, 1, 0, 1]]), np.array([[1, 0, 1, 1]])) == 0.5\n",
    "\n",
    "def cost(a, y):\n",
    "    m = y.shape[1]\n",
    "    return np.sum(-(y * np.log(a) + (1 - y) * np.log(1 - a))) / m\n",
    "\n",
    "def compute_gradients(X, W, b, a, y):\n",
    "    m = y.shape[1]\n",
    "    dims = W.shape[0]\n",
    "    dz = a - y\n",
    "    db = np.sum(dz) / m\n",
    "    dW = np.sum(np.repeat(dz, dims, axis=0) * X, axis=1).reshape(dims, 1) / m\n",
    "\n",
    "    return {'db': db, 'dW': dW}\n",
    "\n",
    "def descend_gradient(X, y, num_iterations, learning_rate):\n",
    "    W = np.zeros((VOCAB_SIZE, 1))\n",
    "    b = 0\n",
    "    for i in range(num_iterations):\n",
    "        a = compute_activations(X, W, b)\n",
    "        grads = compute_gradients(X, W, b, a, y)\n",
    "        W -= learning_rate * grads['dW']\n",
    "        b -= learning_rate * grads['db']\n",
    "        yield (i, W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost on iteration 0: 0.6400143757423893 w/ accuracy 0.6747619972799689, 0 tp, 0 fp, and 1674 fn\n",
      "cost on iteration 100: 0.35916714631876157 w/ accuracy 0.7868661356129785, 645 tp, 68 fp, and 1029 fn\n",
      "cost on iteration 200: 0.3355609633945766 w/ accuracy 0.8055177773460268, 748 tp, 75 fp, and 926 fn\n",
      "cost on iteration 300: 0.3234891078285909 w/ accuracy 0.814066446473674, 795 tp, 78 fp, and 879 fn\n",
      "cost on iteration 400: 0.3156912955979704 w/ accuracy 0.8181464931027783, 814 tp, 76 fp, and 860 fn\n",
      "cost on iteration 500: 0.3100675147662518 w/ accuracy 0.8208665241888479, 829 tp, 77 fp, and 845 fn\n",
      "cost on iteration 600: 0.30574006514916496 w/ accuracy 0.8251408587526715, 852 tp, 78 fp, and 822 fn\n",
      "cost on iteration 700: 0.3022644129049357 w/ accuracy 0.8259180104915484, 856 tp, 78 fp, and 818 fn\n",
      "cost on iteration 800: 0.29938650466121036 w/ accuracy 0.8278608898387411, 867 tp, 79 fp, and 807 fn\n",
      "cost on iteration 900: 0.29694848570200033 w/ accuracy 0.829415193316495, 875 tp, 79 fp, and 799 fn\n",
      "cost on iteration 1000: 0.2948460632443792 w/ accuracy 0.8299980571206528, 879 tp, 80 fp, and 795 fn\n",
      "cost on iteration 1100: 0.29300701584528444 w/ accuracy 0.830969496794249, 884 tp, 80 fp, and 790 fn\n",
      "cost on iteration 1200: 0.2913794368114425 w/ accuracy 0.8323295123372838, 893 tp, 82 fp, and 781 fn\n",
      "cost on iteration 1300: 0.2899248772174463 w/ accuracy 0.8327180882067223, 895 tp, 82 fp, and 779 fn\n",
      "cost on iteration 1400: 0.2886141355858912 w/ accuracy 0.8336895278803186, 898 tp, 80 fp, and 776 fn\n",
      "cost on iteration 1500: 0.2874245612949763 w/ accuracy 0.8352438313580727, 905 tp, 79 fp, and 769 fn\n",
      "cost on iteration 1600: 0.28633826550769326 w/ accuracy 0.8371867107052652, 916 tp, 80 fp, and 758 fn\n",
      "cost on iteration 1700: 0.285340898113279 w/ accuracy 0.8371867107052652, 916 tp, 80 fp, and 758 fn\n",
      "cost on iteration 1800: 0.28442078976560253 w/ accuracy 0.8381581503788614, 922 tp, 81 fp, and 752 fn\n",
      "cost on iteration 1900: 0.2835683363619933 w/ accuracy 0.8389353021177385, 926 tp, 81 fp, and 748 fn\n",
      "cost on iteration 2000: 0.2827755486491078 w/ accuracy 0.8399067417913347, 931 tp, 81 fp, and 743 fn\n"
     ]
    }
   ],
   "source": [
    "for (i, W, b) in descend_gradient(num_iterations=2001, learning_rate=2.0, **training_set):\n",
    "    if i % 100 == 0:\n",
    "        a = compute_activations(training_set['X'], W, b)\n",
    "        curr_cost = cost(a, training_set['y'])\n",
    "        predictions = predict(a)\n",
    "        acc = accuracy(predictions, training_set['y'])\n",
    "        fp = false_positives(predictions, training_set['y'])\n",
    "        fn = false_negatives(predictions, training_set['y'])\n",
    "        tp = true_positives(predictions, training_set['y'])\n",
    "        print(f\"cost on iteration {i}: {curr_cost} w/ accuracy {acc}, {tp} tp, {fp} fp, and {fn} fn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- example row 2535\n",
      "Under the authority of the Attorney General, the Director of the Federal Bureau of Investigation (FBI) shall be responsible for the operation of the NCIJTF. This authority does not allow the Director of the FBI to direct the operations of other agencies. The Director of the FBI shall ensure that participants share the methodology and, to the extent appropriate, case information related to criminal cyber intrusion investigations among law enforcement organizations represented in the NCIJTF in accordance with paragraphs 32 - 33. [Ref. reqs. 1143.52 and 1143.53]\n",
      "['under', 'author', 'attorney', 'general', 'director', 'feder', 'bureau', 'investig', 'fbi', 'shall', 'respons', 'oper', 'ncijtf', 'author', 'doe', 'not', 'allow', 'director', 'fbi', 'direct', 'oper', 'other', 'agenc', 'director', 'fbi', 'shall', 'ensur', 'particip', 'share', 'methodolog', 'extent', 'appropri', 'case', 'inform', 'relat', 'crimin', 'cyber', 'intrus', 'investig', 'among', 'law', 'enforc', 'organ', 'repres', 'ncijtf', 'accord', 'paragraph', 'ref', 'req']\n"
     ]
    }
   ],
   "source": [
    "def print_true_positives(maximum=10):\n",
    "    found = 0\n",
    "    for i in range(training_set_size):\n",
    "        if predictions[0][i] and training_set['y'][0][i]:\n",
    "            orig_index = example_ordering.index(i)\n",
    "            df_row = df.loc[example_ordering[i]]\n",
    "            print(f'-- example row {orig_index}')\n",
    "            print(df_row['reqText'])\n",
    "            print(df_row['reqTextTokenized'])\n",
    "            assert df_row[LABEL_TO_TRAIN] == True\n",
    "            found += 1\n",
    "            if found == maximum:\n",
    "                return\n",
    "\n",
    "print_true_positives(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
